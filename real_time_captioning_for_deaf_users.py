# -*- coding: utf-8 -*-
"""Real-Time Captioning for Deaf Users.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ka4GNuviecHjTFmF2Tpj94cEqddzmrgC
"""

!pip install openai-whisper transformers gradio torch soundfile

!pip install openai-whisper gradio torch soundfile transformers fpdf

!apt update && apt install -y ffmpeg

import whisper
import gradio as gr
import torch
import soundfile as sf
from transformers import pipeline
from fpdf import FPDF

# Load Whisper Model (Tiny for fast performance)
model = whisper.load_model("base")

# Load Sentiment Analysis Model (Optional)
sentiment_model = pipeline("sentiment-analysis")

# Supported Languages for Transcription
LANGUAGES = {
    "English": "en",
    "Urdu": "ur",
    "French": "fr",
    "Spanish": "es",
    "Chinese": "zh",
    "German": "de",
    "Arabic": "ar"
}

def transcribe_audio(audio_file, language):
    """Transcribes uploaded audio in the selected language and performs sentiment analysis."""

    # Read the audio file
    audio, samplerate = sf.read(audio_file)

    # Save as a temporary WAV file
    wav_file = "temp_audio.wav"
    sf.write(wav_file, audio, samplerate)

    # Transcribe with Whisper
    result = model.transcribe(wav_file, language=LANGUAGES[language])
    text = result["text"]

    # Perform sentiment analysis (optional)
    sentiment = sentiment_model(text)[0] if text.strip() else {"label": "Neutral", "score": 0}

    # Color code sentiment
    sentiment_colors = {"POSITIVE": "🟢 Positive", "NEGATIVE": "🔴 Negative", "NEUTRAL": "🟡 Neutral"}
    sentiment_label = sentiment_colors.get(sentiment["label"].upper(), "⚪ Neutral")

    return text, sentiment_label

def export_to_txt(text):
    """Saves transcription as a TXT file."""
    file_path = "transcription.txt"
    with open(file_path, "w", encoding="utf-8") as file:
        file.write(text)
    return file_path

def export_to_pdf(text):
    """Saves transcription as a PDF file."""
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    pdf.multi_cell(0, 10, text)
    file_path = "transcription.pdf"
    pdf.output(file_path)
    return file_path

def refresh_app():
    """Clears all fields and resets the UI."""
    return None, "English", "", ""

# 🎨 Custom Theme for a Beautiful Frontend
css = """
h1 { text-align: center; font-size: 30px; color: #ffffff; margin-bottom: 20px; }
.gradio-container { background: #1e1e2e; color: white; font-family: 'Arial', sans-serif; padding: 20px; }
.upload-box { border: 2px dashed #ffffff; padding: 20px; text-align: center; font-size: 18px; }
.output-box { background: #2a2a3b; padding: 15px; border-radius: 10px; margin-top: 15px; }
.sentiment-box { font-size: 20px; font-weight: bold; }
"""

# 🚀 Beautiful Gradio UI
with gr.Blocks(css=css) as app:
    gr.Markdown("# 🦻 Real-Time Captioning for Deaf Users")
    gr.Markdown("### Upload an audio file, select a language, and get real-time captions with sentiment analysis. Export your transcription as TXT or PDF!")

    with gr.Row():
        audio_input = gr.Audio(type="filepath", label="🎤 Upload an Audio File")
        language_input = gr.Dropdown(list(LANGUAGES.keys()), label="🌍 Select Language", value="English")

    with gr.Row():
        transcript_output = gr.Textbox(label="📝 Transcription", elem_classes=["output-box"])
        sentiment_output = gr.Textbox(label="💬 Sentiment Analysis", elem_classes=["sentiment-box"])

    transcribe_btn = gr.Button("🔍 Transcribe")
    transcribe_btn.click(transcribe_audio, inputs=[audio_input, language_input], outputs=[transcript_output, sentiment_output])

    with gr.Row():
        txt_download_btn = gr.Button("📄 Export as TXT")
        pdf_download_btn = gr.Button("📜 Export as PDF")
        refresh_btn = gr.Button("🔄 Refresh")

    txt_download_btn.click(export_to_txt, inputs=[transcript_output], outputs=gr.File(label="Download TXT"))
    pdf_download_btn.click(export_to_pdf, inputs=[transcript_output], outputs=gr.File(label="Download PDF"))

    # Refresh Button Functionality
    refresh_btn.click(refresh_app, inputs=[], outputs=[audio_input, language_input, transcript_output, sentiment_output])

app.launch()